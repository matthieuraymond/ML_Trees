function [EmoTree] = CreateEmoTree(originalTree, originalAUs, EmoBinaryTarget)        
    %OP is AU index
    %KIDS is an array of 1 row and two columns corresponding to the child nodes
    %CLASS is either 0 or 1 (value of leaf)
    EmoTree = struct('op', null, 'kids', null, 'class', null);
    %AUindex = 0;
    %AUindex = AUindex + 1;

    notLeaf = true;
    
    % FIGURE OUT CURRENT AU!!! FIGURE OUT THE WHOLE CASE MEANING
    % *************** CASE 1: CURRENT AU ISLEAF *****************
    OnesSum == 0;
    AUOnesSum = 0;
    AUZerosSum = 0;
    
    for w = 1:EmoBinaryTarget
        if (EmoBinaryTarget(w) == 1)
            OnesSum = OnesSum + 1;
                    
        % check which value of AU is leaf
        if (currentAU(w) == 1) % leaf is pos AU
            AUOnesSum = AUOnesSum + 1;
        else % leaf is neg AU
            AUZerosSum = AUZerosSum +1;
        end
    end      
    
    % set value of AU as leaf
    if (OnesSum == AUOnesSum) % set value 1 of AU as leaf
        EmoTree.op = w;
        EmoTree.class = 1;
        notLeaf = false;
    else if (OnesSum == AUZerosSum) % set valuse 0 of AU as leaf
        EmoTree.op = w;
        EmoTree.class = 0;
        notLeaf = false;
    end 
    % *************** END CASE 1: CURRENT AU ISLEAF *****************

    %*************** CASE 2: TREE IS EMPTY => MUST BE LEAF **************
    if (isempty(originalAUs))
        notLeaf = false;
        EmoTree.op = AUindex;
        EmoTree.class = manorityValue(EmoBinaryTarget);
    end
    %*************** END CASE 2: TREE IS EMPTY => MUST BE LEAF **********
   
    %*************** CASE 3: INTERNAL NODE (NOT LEAF) *******************
    %choosing best attribute based on info gain     
    if (notleaf)
        %calculate entropy for current level/current function call
        entropyEmoBinaryTarget = CalcEntropy(EmoBinaryTarget);
        
        for j = 1:length(originalAUs) % traverses columns
            currentAU = originalTree(1:length(originalTree), j);
            AUsIGs = zeros (length(originalAUs),1);
            AUsIGs(j) = CalcInfoGain(entropyEmoBinaryTarget, currentAU);
        end
        
        result = chooseBestDecisionAttribute(AUsIGs, originalAUs);
        EmoTree.op = result.bestAU;
        bestAU = result.AUcolumn;
        originalAUs = result.originalAUs;
        originalTree(result.index, :) = [];
        
        % create subtrees (split)
        leftMatrix = [];
        rightMatrix = []; 
        leftEmoBinaryTarget = [];
        rightEmoBinaryTarget = [];
        
        % create right subtree
        for z =1:length(bestAU)
            if (bestAU(z) == 1)
                rightMatrix = [rightMatrix; originalTree(z,:)];  % check syntax
                rightEmoBinaryTarget = [rightEmoBinaryTarget; EmoBinaryTarget(z, 1)];
            end
        end
        
        % create left subtree
        for w =1:length(bestAU)
            if (bestAU(w) == 0)
                leftMatrix = [leftMatrix; originalTree(w,:)]; % check syntax
                leftEmoBinaryTarget = [leftEmoBinaryTarget; EmoBinaryTarget(w, 1)];
            end
        end
  
       EmoTree.kids = [leftMatrix, rightMatrix];
      
       if (isempty(rightMatrix))
           EmoTree.class = manorityValue(EmoBinaryTarget);
       else
           CreateEmoTree(EmoBinaryTarget, originalTree, originalAUs); % right side recursion
       end
            
       if (isempty(leftMatrix))
           EmoTree.class = manorityValue(EmoBinaryTarget);
       else
           CreateEmoTree(EmoBinaryTarget, originalTree, originalAUs); % left side recursion
       end
    end
    %*************** END CASE 3: INTERNAL NODE (NOT LEAF) *******************
end
            
%{
function DECISION-TREE-LEARNING(examples,attributes,binary_targets) returns a decision tree for a given target label
***** CASE 1: CURRENT AU ISLEAF *******
if all examples have the same value of binary_targets
    then return a leaf node with this value

***** CASE 2: TREE IS EMPTY => MUST BE LEAF *******
else if attributes is empty
    then return a leaf node with value = MAJORITY-VALUE(binary_targets)

***** CASE 3: INTERNAL NODE (NOT LEAF) *******
else
    best_attribute ? CHOOSE-BEST-DECISION-ATTRIBUTE(examples,attributes, binary_targets)
    tree ? a new decision tree with root as best_attribute
    for each possible value ?i of best_attribute do (note that there are 2 values: 0 and 1)
    add a branch to tree corresponding to best_attibute = ?i
    {examplesi , binary_targets i}? {elements of examples with best_attribute = ?i and the corresponding binary_targetsi }
    if examplesi is empty
        then return a leaf node with value = MAJORITY-VALUE(binary_targets)
    else
    subtree ? DECISION-TREE-LEARNING(examplesi ,attributes-{best_attribute}, binary_targetsi)
}%